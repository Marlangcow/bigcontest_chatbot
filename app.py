import os
from dotenv import load_dotenv

import numpy as np
import pandas as pd
import streamlit as st

from transformers import AutoTokenizer, AutoModel
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.chains import RetrievalQA
from langchain.retrievers import EnsembleRetriever
from sentence_transformers import util
from sentence_transformers import SentenceTransformer
from google.cloud import dialogflow_v2 as dialogflow
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain.docstore.document import Document
from transformers import BitsAndBytesConfig, AutoModelForCausalLM
from langchain_core.runnables import RunnableLambda
from langchain.chains import LLMChain
import google.generativeai as genai
from typing import List, Dict
from langchain_community.embeddings import (
    SentenceTransformerEmbeddings,
    HuggingFaceEmbeddings,
)
from langchain_community.retrievers import BM25Retriever
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

import faiss
import json
import torch

# 1. ì„¤ì • ë° ìƒìˆ˜

# CONFIG ê°ì²´ë¥¼ importë¬¸ ë‹¤ìŒ, ë‹¤ë¥¸ ì½”ë“œë“¤ ì´ì „ì— ì •ì˜
CONFIG = {
    'model_name': "jhgan/ko-sroberta-multitask",
    'similarity_threshold': 0.7,
    'retriever_weights': [0.6, 0.4],
    'search_params': {
        'k': 4,
        'fetch_k': 10,
        'lambda_mult': 0.6,
        'score_threshold': 0.6
    }
}

# .env íŒŒì¼ ê²½ë¡œ ì§€ì •
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY_1")

# ìƒë‹¨ì— CSS ìŠ¤íƒ€ì¼ ì •ì˜
STYLES = """
<style>
/* Selectbox ë ˆì´ë¸” ìˆ¨ê¸°ê¸° ë° ì—¬ë°± ì¡°ì • */
.stSelectbox label { 
    display: none; 
}
.stSelectbox div[role='combobox'] { 
    margin-top: -20px; 
}

/* Radio button ë ˆì´ë¸” ìˆ¨ê¸°ê¸° ë° ì—¬ë°± ì¡°ì • */
.stRadio > label { 
    display: none; 
}
.stRadio > div { 
    margin-top: -20px; 
}
</style>
"""

st.set_page_config(page_title="ğŸŠê°ê·¤í†¡")
st.markdown(STYLES, unsafe_allow_html=True)

# ë©”ì¸ UI
st.title("ğŸŠê°ê·¤í†¡, ì œì£¼ë„ ì—¬í–‰ ë©”ì´íŠ¸")
st.write("")
st.info("ì œì£¼ë„ ì—¬í–‰ ë©”ì´íŠ¸ ê°ê·¤í†¡ì´ ì œì£¼ë„ì˜ ë°©ë°©ê³¡ê³¡ì„ ì•Œë ¤ì¤„ê²Œ ğŸï¸")

# ì´ë¯¸ì§€ ë¡œë“œ ì„¤ì •
image_path = "https://img4.daumcdn.net/thumb/R658x0.q70/?fname=https://t1.daumcdn.net/news/202105/25/linkagelab/20210525013157546odxh.jpg"
image_html = f"""
<div style="display: flex; justify-content: center;">
    <img src="{image_path}" alt="centered image" width="50%">
</div>
"""
st.markdown(image_html, unsafe_allow_html=True)

# ëŒ€í™” ì´ˆê¸°í™” í•¨ìˆ˜ ì •ì˜
def clear_chat_history():
    st.session_state.messages = [
        {"role": "assistant", "content": "ì–´ë–¤ ê³³ì„ ì°¾ì•„ì¤„ê¹Œ?"}
    ]
    
# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.title("ğŸŠê°ê·¤í†¡ì´ ë‹¤ ì°¾ì•„ì¤„ê²ŒğŸŠ")
    st.write("")
    
    st.subheader("ì›í•˜ëŠ” #í‚¤ì›Œë“œë¥¼ ê³¨ë¼ë´")
    keywords = st.selectbox(
        "",
        [
            "ì°©í•œê°€ê²©ì—…ì†Œ",
            "ëŸ­ì…”ë¦¬íŠ¸ë˜ë¸”ì¸ì œì£¼",
            "ìš°ìˆ˜ê´€ê´‘ì‚¬ì—…ì²´",
            "ë¬´ì¥ì• ê´€ê´‘",
            "ì•ˆì „ì—¬í–‰ìŠ¤íƒ¬í”„",
            "í–¥í† ìŒì‹",
            "í•œì‹",
            "ì¹´í˜",
            "í•´ë¬¼ëšë°°ê¸°",
            "ëª¸êµ­",
            "í•´ì¥êµ­",
            "ìˆ˜ì œë²„ê±°",
            "í‘ë¼ì§€",
            "í•´ì‚°ë¬¼",
            "ì¼ì‹",
        ],
        key="keywords",
    )
    
    st.subheader("ì–´ë–¤ ë™ë„¤ê°€ ê¶ê¸ˆí•´?")
    locations = st.selectbox(
        "",
        (
            "êµ¬ì¢Œ",
            "ëŒ€ì •",
            "ì„œê·€í¬",
            "ì•ˆë•",
            "ìš°ë„",
            "ì• ì›”",
            "ì¡°ì²œ",
            "ì œì£¼ì‹œë‚´",
            "ì¶”ì",
            "í•œë¦¼",
            "í•œê²½",
        ),
        key="locations"
    )
    st.write("")

    st.subheader("í‰ì  ëª‡ì  ì´ìƒì„ ì°¾ê³  ì‹¶ì–´?")
    score = st.slider(
        "ë¦¬ë·° í‰ì ", 
        min_value=3.0, 
        max_value=5.0, 
        value=4.0, 
        step=0.05,
        key="score"
    )
    
    st.write("")
    st.button("ëŒ€í™” ì´ˆê¸°í™”", on_click=clear_chat_history, key="clear_chat_sidebar")
    st.caption("ğŸ“¨ ê°ê·¤í†¡ì— ë¬¸ì˜í•˜ì„¸ìš” [Send email](mailto:happily2bus@gmail.com)")


      
# HuggingFaceEmbeddings ê°ì²´ ì´ˆê¸°í™”
embedding = HuggingFaceEmbeddings(model_name=CONFIG['model_name'])

# Google Generative AI API ì„¤ì • ë¶€ë¶„ ì´ì „ì— memory ì •ì˜
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# ê·¸ ë‹¤ìŒ llmê³¼ chain ì •ì˜
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    temperature=0.2,
    top_p=0.85,
    frequency_penalty=0.1,
    google_api_key=google_api_key,
    credentials=None
)

PROMPT_TEMPLATE = """
    ### ì—­í• 
    ë‹¹ì‹ ì€ ì œì£¼ë„ ë§›ì§‘ê³¼ ê´€ê´‘ì§€ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ë°›ì„ ë•Œ ë…¼ë¦¬ì ìœ¼ë¡œ ìƒê°í•œ í›„ ë‹¨ê³„ë³„ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    ë³µì¡í•œ ì§ˆë¬¸ì¼ìˆ˜ë¡ ì²œì²œíˆ ìƒê°í•˜ê³  ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œê·¼í•˜ê³  ì •ê²¨ìš´ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

    ### Chain of Thought ë°©ì‹ ì ìš©:
    1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    2. ì§ˆë¬¸ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
    3. ê·¸ í›„ì— ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë‚˜ ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ì„± ìˆëŠ” ë§›ì§‘ê³¼ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    4. ë‹¨ê³„ë¥¼ ë‚˜ëˆ„ì–´ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.

    ### ì§€ì‹œì‚¬í•­
    1. ê²€ìƒ‰í•  ë‚´ìš©ì´ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´ ì‚¬ìš©ìì—ê²Œ ë°˜ë¬¸í•˜ì„¸ìš”. ì´ëŠ” ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤. ë‹¨, ë‘ë²ˆ ì´ìƒ ë°˜ë¬¸í•˜ì§€ ë§ˆì„¸ìš”. ë§Œì•½ ì‚¬ìš©ìê°€ ìœ„ì¹˜ë¥¼ ëª¨ë¥¸ë‹¤ë©´ ì œì¼ í‰ì ì´ ì¢‹ì€ 3ê°œì˜ ì‹ë‹¹+ì¹´í˜ì™€ 3ê°œì˜ ê´€ê´‘ì§€ë¥¼ ì•ˆë‚´í•´ì£¼ì„¸ìš”.
    2. ë‹µë³€ì„ í•˜ëŠ” ê²½ìš° ì–´ë–¤ ë¬¸ì„œë¥¼ ì¸ìš©í–ˆëŠ”ì§€ (í‚¤:ê°’) ì—ì„œ í‚¤ëŠ” ì œì™¸í•˜ê³  ê°’ë§Œ ë‹µë³€ ë’¤ì— ì–¸ê¸‰í•˜ì„¸ìš”.
      (mct_docs: ì‹ í•œì¹´ë“œ ê°€ë§¹ì  - ìš”ì‹ì—…, month_docs: ë¹„ì§“ì œì£¼ - ì›”ë³„ ì¡°íšŒìˆ˜, wkday_docs: ë¹„ì§“ì œì£¼ - ìš”ì¼ë³„ ì¡°íšŒìˆ˜, mop_docs: ê´€ê´‘ì§€ í‰ì ë¦¬ë·°, menu_docs: ì¹´ì¹´ì˜¤ë§µ ê°€ê²Œ ë©”ë‰´, visit_docs: ë¹„ì§“ì œì£¼ - ì—¬í–‰ì§€ ì •ë³´, kakaomap_reviews_docs: ì¹´ì¹´ì˜¤ë§µ ë¦¬ë·°)
    4. ì¶”ì²œ ì´ìœ ì™€ ê±°ë¦¬, ì†Œìš” ì‹œê°„, í•µì‹¬í‚¤ì›Œë“œ 3ê°œ, í‰ì ê³¼ ë¦¬ë·°ë“¤ë„ ë³´ì—¬ì£¼ì„¸ìš”. ë§Œì•½ ë¦¬ë·°ê°€ ì—†ëŠ” ê³³ì´ë¼ë©´ ("ì•„ì§ ì‘ì„±ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.") ë¼ê³  í•´ì£¼ì„¸ìš”.
    5. 4ë²ˆì˜ ì§€ì‹œì‚¬í•­ê³¼ í•¨ê»˜ íŒë§¤ ë©”ë‰´ 2ê°œ, ê°€ê²©ì„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.
    6. ì£¼ì†Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ê²€ìƒ‰ë˜ëŠ” ì¥ì†Œë¥¼ ì•„ë˜ ì˜ˆì‹œ ë§í¬ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
      - ë„¤ì´ë²„ ì§€ë„ í™•ì¸í•˜ê¸°: (https://map.naver.com/p/search/ì œì£¼ë„+<place>ì¥ì†Œëª…</place>)
    7. ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì‹ë‹¹ê³¼ ê´€ê´‘ì§€ëª…ì„ ì¶”ì²œí•´ì£¼ì–´ì•¼ í•˜ë©°, %%í‘ë¼ì§€ ë§›ì§‘, íšŸì§‘ 1 ë“± ê°€ê²Œëª…ì´ ëª…í™•í•˜ì§€ ì•Šì€ ë‹µë³€ì€ í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.
    8. ë‹µë³€ ë‚´ìš©ì— ë”°ë¼ í°íŠ¸ì‚¬ì´ì¦ˆ, ë¶ˆë ›, ìˆœì„œ í™œìš©í•˜ê³  ë¬¸ë‹¨ì„ êµ¬ë¶„í•˜ì—¬ ê°€ë…ì„±ì´ ì¢‹ê²Œ í•´ì£¼ì„¸ìš”.

    ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©:
    {search_results}

    ëŒ€í™” ê¸°ë¡:
    {chat_history}

    ì‚¬ìš©ìì˜ ì§ˆë¬¸: {input_text}

    ë…¼ë¦¬ì ì¸ ì‚¬ê³  í›„ ì‚¬ìš©ìì—ê²Œ ì œê³µí•  ë‹µë³€:
    """
    
prompt_template = PromptTemplate(
    input_variables=["input_text", "search_results", "chat_history"],
    template=PROMPT_TEMPLATE
)

# ì²´ì¸ ìƒì„±
chain = LLMChain(
    prompt=prompt_template,
    llm=llm,
    output_parser=StrOutputParser(),
)

# RAG

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Device is {device}.")

# JSON íŒŒì¼ ê²½ë¡œ ì„¤ì •
file_paths = {
    "mct": "/Users/naeun/bigcontest_chatbot/data/mct.json",
    "month": "/Users/naeun/bigcontest_chatbot/data/month.json",
    "wkday": "/Users/naeun/bigcontest_chatbot/data/wkday.json",
    "mop_sentiment": "/Users/naeun/bigcontest_chatbot/data/merge_mop_sentiment.json",
    "menu": "/Users/naeun/bigcontest_chatbot/data/mct_menus.json",
    "visit_jeju": "/Users/naeun/bigcontest_chatbot/data/visit_jeju.json",
    "kakaomap_reviews": "/Users/naeun/bigcontest_chatbot/data/kakaomap_reviews.json",
}

# 2. ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
def initialize_retriever(db):
    return db.as_retriever(
        search_type="mmr",
        search_kwargs=CONFIG['search_params']
    )

# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# JSON íŒŒì¼ ë¡œë“œ
def load_json_files(file_paths):
    data = {}
    for key, path in file_paths.items():
        try:
            with open(path, "r", encoding="utf-8") as f:
                data[key] = json.load(f)
        except FileNotFoundError:
            print(f"File not found: {path}")
        except json.JSONDecodeError:
            print(f"Error decoding JSON from file: {path}")
    return data

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹œ ì˜¤ë¥˜ ì²˜ë¦¬ í•¨ìˆ˜ ê°œì„ 
def load_faiss_indexes(index_paths):
    indexes = {}
    for key, path in index_paths.items():
        try:
            if not os.path.exists(path):
                print(f"Warning: Index file not found: {path}")
                continue  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            indexes[key] = faiss.read_index(path)  # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        except faiss.FaissException as e:
            print(f"FAISS error loading index '{key}': {e}")
        except Exception as e:
            print(f"Unexpected error loading index '{key}': {e}")
    return indexes

# 4. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤

# í†µí•©ëœ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ë¥¼ ë¨¼ì € ì •ì˜
def get_chatbot_response(query, memory, chain):
    try:
        # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
        search_results = flexible_function_call_search(query)
        if not search_results:
            return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        search_results_str = "\n".join(
            [doc.page_content for doc in search_results]
        ).strip()
        if not search_results_str:
            return "ê²€ìƒ‰ëœ ë‚´ìš©ì´ ì—†ì–´ì„œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ëŒ€í™” ê¸°ë¡ ë¡œë“œ
        chat_history = memory.load_memory_variables({}).get("chat_history", "")

        # LLMChainì— ì „ë‹¬í•  ì…ë ¥ ë°ì´í„° êµ¬ì„±
        input_data = {
            "input_text": query,
            "search_results": search_results_str,
            "chat_history": chat_history,
        }

        try:
            output = chain(input_data)
            output_text = output.get("text", str(output))
        except Exception as e:
            print(f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        # ëŒ€í™” ê¸°ë¡ì— ì…ë ¥ ë° ì¶œë ¥ ì €ì¥
        memory.save_context({"input": query}, {"output": output_text})
        return output_text

    except Exception as e:
        print(f"ê²€ìƒ‰ ë˜ëŠ” ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

# ì„ë² ë”© ìºì‹± ì¶”ê°€
@st.cache_data(ttl=3600)
def get_embedding(text):
    return embedding.embed_query(text)

def flexible_function_call_search(query):
    try:
        # ì…ë ¥ ì¿¼ë¦¬ì˜ ì„ë² ë”©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        input_embedding = get_embedding(query)

        # ë¦¬íŠ¸ë¦¬ë²„ì™€ ì„¤ëª…ì„ ì •ì˜
        retrievers_info = {
            "mct": {
                "retriever": mct_retriever,
                "description": "ì‹ë‹¹ ì •ë³´ ë° ì—°ì´ìš© ë¹„ì¤‘ ë° ê¸ˆì•¡ ë¹„ì¤‘",
            },
            "month": {
                "retriever": month_retriever,
                "description": "ê´€ê´‘ì§€ ì›”ë³„ ì¡°íšŒìˆ˜",
            },
            "wkday": {
                "retriever": wkday_retriever,
                "description": "ì£¼ë³„ ì¼ë³„ ì¡°íšŒìˆ˜ ë° ì—°ë ¹ë³„ ì„±ë³„ë³„ ì„ í˜¸ë„",
            },
            "mop": {
                "retriever": mop_retriever,
                "description": "ê´€ê´‘ì§€ ì „ì²´ ê°ì„±ë¶„ì„ ë°ì´í„°",
            },
            "menus": {
                "retriever": menus_retriever,
                "description": "ì‹ë‹¹ëª… ë° ë©”ë‰´ ë° ê¸ˆì•¡",
            },
            "visit": {
                "retriever": visit_retriever,
                "description": "ê´€ê´‘ì§€ í•µì‹¬ ì›Œë“œ ë° ì •ë³´",
            },
            "kakaomap_reviews": {
                "retriever": kakaomap_reviews_retriever,
                "description": "ë¦¬ë·° ë°ì´í„°",
            },
        }

        # ê° ë¦¬íŠ¸ë¦¬ë²„ì˜ ì„¤ëª…ì„ ì„ë² ë”©í•©ë‹ˆë‹¤.
        retriever_embeddings = {
            key: embedding.embed_query(info["description"])
            for key, info in retrievers_info.items()
        }

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = {
            key: util.cos_sim(input_embedding, embed).item()
            for key, embed in retriever_embeddings.items()
        }

        # ìœ ì‚¬ë„ê°€ ì„ê³„ê°’ ì´ìƒì¸ ë¦¬íŠ¸ë¦¬ë²„ ì„ íƒ
        similarity_threshold = CONFIG['similarity_threshold']
        selected_retrievers = sorted(
            [(key, sim) for key, sim in similarities.items() if sim > similarity_threshold],
            key=lambda x: x[1],
            reverse=True,
        )

        # ì„ íƒëœ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì‚¬ìš©í•´ ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
        results = []
        for retriever_key, _ in selected_retrievers:
            try:
                retriever = retrievers_info[retriever_key]["retriever"]
                result = retriever.get_relevant_documents(query)
                results.extend(result)
            except Exception as e:
                print(f"{retriever_key} ë¦¬íŠ¸ë¦¬ë²„ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

        return results if results else "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì–´ë–¤ ê³³ì„ ì°¾ì•„ì¤„ê¹Œ?"}
    ]

# ê·¸ ë‹¤ìŒ ì±„íŒ… ì…ë ¥ ì²˜ë¦¬ ì½”ë“œ
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”", key="user_input"):  # := ì—°ì‚°ì ì‚¬ìš©
    with st.spinner("ğŸ¤” ìƒê°í•˜ëŠ” ì¤‘..."):
        try:
            enhanced_prompt = f"""
                ì‚¬ìš©ì ì…ë ¥: {prompt}
                í‚¤ì›Œë“œ: {st.session_state.keywords if 'keywords' in st.session_state else 'ì—†ìŒ'}
                ì§€ì—­: {st.session_state.locations if 'locations' in st.session_state else 'ì—†ìŒ'}
                ìµœì†Œ í‰ì : {st.session_state.score if 'score' in st.session_state else 'ì—†ìŒ'}
            """.strip()
            
            response = get_chatbot_response(enhanced_prompt, memory, chain)
            
            st.session_state.messages.append({"role": "user", "content": prompt})
            st.session_state.messages.append({"role": "assistant", "content": response})
            
            with st.chat_message("assistant", avatar="ğŸŠ"):
                st.markdown(response)
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.error("ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# í…ìŠ¤íŠ¸ í‘œì‹œ
st.write("")

# ë©”ì‹œì§€ í‘œì‹œ - í•œ ë²ˆë§Œ ì‹¤í–‰
for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar="ğŸ¬"):
        st.write(message["content"])

# ì‚¬ì´ë“œë°”ì— ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
st.sidebar.button("ëŒ€í™” ì´ˆê¸°í™”", on_click=clear_chat_history)

# @st.cache_resource ë°ì½”ë ˆì´í„°ë¥¼ ìˆ˜ì •í•˜ê³  TTL ì¶”ê°€
@st.cache_resource(ttl=3600)  # 1ì‹œê°„ ìºì‹œ
def initialize_databases():
    try:
        # JSON ë°ì´í„° ë¡œë“œ
        data = load_json_files(file_paths)
        
        # ì§„í–‰ ìƒí™©ì„ ë³´ì—¬ì£¼ëŠ” progress bar ì¶”ê°€
        progress_text = "ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘..."
        my_bar = st.progress(0, text=progress_text)
        
        # Document ê°ì²´ ìƒì„± ë° FAISS DB ì´ˆê¸°í™”ë¥¼ ë‹¨ê³„ë³„ë¡œ ì§„í–‰
        dbs = {}
        total_steps = 7  # ì´ ì²˜ë¦¬í•´ì•¼ í•  DB ìˆ˜
        
        # ê° ë°ì´í„°ì…‹ ì²˜ë¦¬ë¥¼ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
        def process_dataset(data_key, data_items, step):
            docs = [Document(page_content=item.get("ê°€ê²Œëª…" if "ê°€ê²Œ" in data_key else "ê´€ê´‘ì§€ëª…", ""), 
                           metadata=item) for item in data_items]
            db = FAISS.from_documents(documents=docs, embedding=embedding)
            my_bar.progress((step + 1) / total_steps, 
                          text=f"{progress_text} ({step + 1}/{total_steps})")
            return db
        
        # ê° ë°ì´í„°ì…‹ ìˆœì°¨ì  ì²˜ë¦¬
        datasets = [
            ("mct", data["mct"]),
            ("month", data["month"]),
            ("wkday", data["wkday"]),
            ("mop_sentiment", data["mop_sentiment"]),
            ("menu", data["menu"]),
            ("visit_jeju", data["visit_jeju"]),
            ("kakaomap_reviews", data["kakaomap_reviews"])
        ]
        
        for i, (key, items) in enumerate(datasets):
            dbs[f"{key}_db"] = process_dataset(key, items, i)
        
        my_bar.empty()  # progress bar ì œê±°
        return dbs
        
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ì±—ë´‡ ì‹œì‘ ì‹œ ì´ì „ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
def main():
    try:
        with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘..."):
            # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            dbs = initialize_databases()
            if dbs is None:
                st.error("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨")
                return
            # Retriever ì´ˆê¸°í™”
            global mct_retriever, month_retriever, wkday_retriever, mop_retriever
            global menus_retriever, visit_retriever, kakaomap_reviews_retriever
            
            # BM25 ê²€ìƒ‰ê¸° ìƒì„±
            mct_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in mct_docs])
            month_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in month_docs])
            wkday_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in wkday_docs])
            mop_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in mop_docs])
            menus_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in menu_docs])
            visit_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in visit_docs])
            kakaomap_reviews_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in kakaomap_reviews_docs])
            
            
            # Retriever ì´ˆê¸°í™”
            mct_retriever = dbs["mct_db"].as_retriever()
            month_retriever = dbs["month_db"].as_retriever()
            wkday_retriever = dbs["wkday_db"].as_retriever()
            mop_retriever = dbs["mop_db"].as_retriever()
            menus_retriever = dbs["menus_db"].as_retriever()
            visit_retriever = dbs["visit_db"].as_retriever()
            kakaomap_reviews_retriever = dbs["kakaomap_reviews_db"].as_retriever()    
    
    except Exception as e:
        st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    
# ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
if __name__ == "__main__":
    main()