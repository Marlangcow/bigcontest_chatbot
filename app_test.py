import os
from dotenv import load_dotenv

import numpy as np
import pandas as pd
import streamlit as st

from transformers import AutoTokenizer, AutoModel
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.chains import RetrievalQA
from langchain.retrievers import EnsembleRetriever
from sentence_transformers import util
from sentence_transformers import SentenceTransformer
from google.cloud import dialogflow_v2 as dialogflow
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain.docstore.document import Document
from transformers import BitsAndBytesConfig, AutoModelForCausalLM
from langchain_core.runnables import RunnableLambda
from langchain.chains import LLMChain
import google.generativeai as genai
from typing import List, Dict
from langchain_community.embeddings import (
    SentenceTransformerEmbeddings,
    HuggingFaceEmbeddings,
)
from langchain_community.retrievers import BM25Retriever
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

import faiss
import json
import torch

# .env íŒŒì¼ ê²½ë¡œ ì§€ì •
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY_1")

# Streamlit App UI
st.set_page_config(page_title="ğŸŠê°ê·¤í†¡")

st.title("ğŸŠê°ê·¤í†¡, ì œì£¼ë„ ì—¬í–‰ ë©”ì´íŠ¸")

st.write("")

st.info("ì œì£¼ë„ ì—¬í–‰ ë©”ì´íŠ¸ ê°ê·¤í†¡ì´ ì œì£¼ë„ì˜ ë°©ë°©ê³¡ê³¡ì„ ì•Œë ¤ì¤„ê²Œ ğŸï¸")

# ì´ë¯¸ì§€ ë¡œë“œ ì„¤ì •
image_path = "https://img4.daumcdn.net/thumb/R658x0.q70/?fname=https://t1.daumcdn.net/news/202105/25/linkagelab/20210525013157546odxh.jpg"
image_html = f"""
<div style="display: flex; justify-content: center;">
    <img src="{image_path}" alt="centered image" width="50%">
</div>
"""
st.markdown(image_html, unsafe_allow_html=True)

# í…ìŠ¤íŠ¸ í‘œì‹œ
st.write("")

# Replicate Credentials
with st.sidebar:
    st.title("ğŸŠê°ê·¤í†¡ì´ ë‹¤ ì°¾ì•„ì¤„ê²ŒğŸŠ")

    st.write("")

    st.subheader("ì›í•˜ëŠ” #í‚¤ì›Œë“œë¥¼ ê³¨ë¼ë´")

    # selectbox ë ˆì´ë¸” ê³µë°± ì œê±°
    st.markdown(
        """
        <style>
        .stSelectbox label {  /* This targets the label element for selectbox */
            display: none;  /* Hides the label element */
        }
        .stSelectbox div[role='combobox'] {
            margin-top: -20px; /* Adjusts the margin if needed */
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    keywords = st.sidebar.selectbox(
        "",
        [
            "ì°©í•œê°€ê²©ì—…ì†Œ",
            "ëŸ­ì…”ë¦¬íŠ¸ë˜ë¸”ì¸ì œì£¼",
            "ìš°ìˆ˜ê´€ê´‘ì‚¬ì—…ì²´",
            "ë¬´ì¥ì• ê´€ê´‘",
            "ì•ˆì „ì—¬í–‰ìŠ¤íƒ¬í”„",
            "í–¥í† ìŒì‹",
            "í•œì‹",
            "ì¹´í˜",
            "í•´ë¬¼ëšë°°ê¸°",
            "ëª¸êµ­",
            "í•´ì¥êµ­",
            "ìˆ˜ì œë²„ê±°",
            "í‘ë¼ì§€",
            "í•´ì‚°ë¬¼",
            "ì¼ì‹",
        ],
        key="keywords",
    )

    st.write("")

    st.subheader("ì–´ë–¤ ì¥ì†Œê°€ ê¶ê¸ˆí•´?")

    # ë ˆì´ë¸” ê³µë°± ì œê±°
    st.markdown(
        """
        <style>
        .stRadio > label {
            display: none;
        }
        .stRadio > div {
            margin-top: -20px;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    locations = st.sidebar.selectbox(
        "",
        (
            "êµ¬ì¢Œ",
            "ëŒ€ì •",
            "ì„œê·€í¬",
            "ì•ˆë•",
            "ìš°ë„",
            "ì• ì›”",
            "ì¡°ì²œ",
            "ì œì£¼ì‹œë‚´",
            "ì¶”ì",
            "í•œë¦¼",
            "í•œê²½",
        ),
    )
    st.write("")

    st.subheader("í‰ì  ëª‡ì  ì´ìƒì„ ì›í•´?")
    score = st.slider("ë¦¬ë·° í‰ì ", min_value=3.0, max_value=5.0, value=4.5, step=0.05)

# ì´ë©”ì¼ ë§í¬
st.sidebar.caption("ğŸ“¨ ê°ê·¤í†¡ì— ë¬¸ì˜í•˜ê¸° [Send email](mailto:happily2bus@gmail.com)")

st.write("")

# Store LLM generated responses
if "messages" not in st.session_state.keys():
    st.session_state.messages = [
        {"role": "assistant", "content": "ì–´ë–¤ ê³³ì„ ì°¾ì•„ì¤„ê¹Œ?"}
    ]

# Display or clear chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar="ğŸ¬"):
        st.write(message["content"])


def clear_chat_history():
    st.session_state.messages = [
        {"role": "assistant", "content": "ì–´ë–¤ ê³³ì„ ì°¾ì•„ì¤„ê¹Œ?"}
    ]


st.sidebar.button("ëŒ€í™” ì´ˆê¸°í™”", on_click=clear_chat_history)

# RAG

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Device is {device}.")


# JSON íŒŒì¼ ë¡œë“œ
def load_json_files(file_paths):
    data = {}
    for key, path in file_paths.items():
        try:
            with open(path, "r", encoding="utf-8") as f:
                data[key] = json.load(f)
        except FileNotFoundError:
            print(f"File not found: {path}")
        except json.JSONDecodeError:
            print(f"Error decoding JSON from file: {path}")
    return data


# FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹œ ì˜¤ë¥˜ ì²˜ë¦¬ í•¨ìˆ˜ ê°œì„ 
def load_faiss_indexes(index_paths):
    indexes = {}
    for key, path in index_paths.items():
        try:
            if not os.path.exists(path):
                print(f"Warning: Index file not found: {path}")
                continue  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            indexes[key] = faiss.read_index(path)  # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        except faiss.FaissException as e:
            print(f"FAISS error loading index '{key}': {e}")
        except Exception as e:
            print(f"Unexpected error loading index '{key}': {e}")
    return indexes


# JSON íŒŒì¼ ê²½ë¡œ ì„¤ì •
file_paths = {
    "mct": "/Users/naeun/bigcontest_chatbot/data/mct.json",
    "month": "/Users/naeun/bigcontest_chatbot/data/month.json",
    "wkday": "/Users/naeun/bigcontest_chatbot/data/wkday.json",
    "mop_sentiment": "/Users/naeun/bigcontest_chatbot/data/merge_mop_sentiment.json",
    "menu": "/Users/naeun/bigcontest_chatbot/data/mct_menus.json",
    "visit_jeju": "/Users/naeun/bigcontest_chatbot/data/visit_jeju.json",
    "kakaomap_reviews": "/Users/naeun/bigcontest_chatbot/data/kakaomap_reviews.json",
}

@st.cache_data
# JSON íŒŒì¼ ë¡œë“œ
data = load_json_files(file_paths)

# FAISS ì¸ë±ìŠ¤ ê²½ë¡œ ì„¤ì •
index_paths = {
    "mct": "/Users/naeun/bigcontest_chatbot/data/faiss_index/mct_index_pq.faiss",
    "month": "/Users/naeun/bigcontest_chatbot/data/faiss_index/month_index_pq.faiss",
    "wkday": "/Users/naeun/bigcontest_chatbot/data/faiss_index/wkday_index_pq.faiss",
    # "mop": "/Users/naeun/bigcontest_chatbot/data/faiss_index/mop_db.faiss",  # ì£¼ì„ ì²˜ë¦¬ëœ ê²½ë¡œ
    "menu": "/Users/naeun/bigcontest_chatbot/data/faiss_index/menu.faiss",
    "visit": "/Users/naeun/bigcontest_chatbot/data/faiss_index/visit_jeju.faiss",
    "kakaomap_reviews": "/Users/naeun/bigcontest_chatbot/data/faiss_index/kakaomap_reviews.faiss",
}

@st.cache_data
# FAISS ì¸ë±ìŠ¤ ë¡œë“œ
faiss_indexes = load_faiss_indexes(index_paths)

# Document ê°ì²´ ìƒì„±
mct_docs = [
    Document(page_content=item.get("ê°€ê²Œëª…", ""), metadata=item) for item in data["mct"]
]
month_docs = [
    Document(page_content=item.get("ê´€ê´‘ì§€ëª…", ""), metadata=item)
    for item in data["month"]
]
wkday_docs = [
    Document(page_content=item.get("ê´€ê´‘ì§€ëª…", ""), metadata=item)
    for item in data["wkday"]
]
mop_docs = [
    Document(page_content=item.get("ê´€ê´‘ì§€ëª…", ""), metadata=item)
    for item in data["mop_sentiment"]
]
menu_docs = [
    Document(page_content=item.get("ê°€ê²Œëª…", ""), metadata=item)
    for item in data["menu"]
]
visit_docs = [
    Document(page_content=item.get("ê´€ê´‘ì§€ëª…", ""), metadata=item)
    for item in data["visit_jeju"]
]
kakaomap_reviews_docs = [
    Document(page_content=item.get("ê´€ê´‘ì§€ëª…", ""), metadata=item)
    for item in data["kakaomap_reviews"]
]

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "jhgan/ko-sroberta-multitask"
device = "cuda" if torch.cuda.is_available() else "cpu"
tokenizer = AutoTokenizer.from_pretrained(model_name)
embedding_model = AutoModel.from_pretrained(model_name).to(device)


# HuggingFaceEmbeddings ê°ì²´ ì´ˆê¸°í™”
embedding = HuggingFaceEmbeddings(model_name=model_name)

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
)

@st.cache_data
# ê° ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ FAISS DBì— ë„£ê¸°
mct_db = FAISS.from_documents(documents=mct_docs, embedding=embedding)
month_db = FAISS.from_documents(documents=month_docs, embedding=embedding)
wkday_db = FAISS.from_documents(documents=wkday_docs, embedding=embedding)
mop_db = FAISS.from_documents(documents=mop_docs, embedding=embedding)
menus_db = FAISS.from_documents(documents=menu_docs, embedding=embedding)
visit_db = FAISS.from_documents(documents=visit_docs, embedding=embedding)
kakaomap_reviews_db = FAISS.from_documents(
    documents=kakaomap_reviews_docs, embedding=embedding
)

@st.cache_data
# ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê²€ìƒ‰ê¸°ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ retriever ë³€ìˆ˜ì— í• ë‹¹
mct_retriever = mct_db.as_retriever()
month_retriever = month_db.as_retriever()
wkday_retriever = wkday_db.as_retriever()
mop_retriever = mop_db.as_retriever()
menus_retriever = menus_db.as_retriever()
visit_retriever = visit_db.as_retriever()
kakaomap_reviews_retriever = kakaomap_reviews_db.as_retriever()


def initialize_retriever(
    db, search_type="mmr", k=4, fetch_k=10, lambda_mult=0.6, score_threshold=0.6
):
    return db.as_retriever(
        search_type=search_type,
        search_kwargs={
            "k": k,
            "fetch_k": fetch_k,
            "lambda_mult": lambda_mult,
            "score_threshold": score_threshold,
        },
    )


# ë¦¬ìŠ¤íŠ¸ë¡œ DBì™€ ì´ë¦„ì„ ë¬¶ì–´ì„œ ì²˜ë¦¬
dbs = {
    "mct": mct_db,
    "month": month_db,
    "wkday": wkday_db,
    "mop": mop_db,
    "menus": menus_db,
    "visit": visit_db,
    "kakaomap_reviews": kakaomap_reviews_db,
}

# ê° DBì— ëŒ€í•´ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
retrievers = {name: initialize_retriever(db) for name, db in dbs.items()}

@st.cache_data
# BM25 ê²€ìƒ‰ê¸° ìƒì„±
mct_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in mct_docs])
month_bm25_retriever = BM25Retriever.from_texts(
    [doc.page_content for doc in month_docs]
)
wkday_bm25_retriever = BM25Retriever.from_texts(
    [doc.page_content for doc in wkday_docs]
)
mop_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in mop_docs])
menus_bm25_retriever = BM25Retriever.from_texts([doc.page_content for doc in menu_docs])
visit_bm25_retriever = BM25Retriever.from_texts(
    [doc.page_content for doc in visit_docs]
)
kakaomap_reviews_bm25_retriever = BM25Retriever.from_texts(
    [doc.page_content for doc in kakaomap_reviews_docs]
)


def initialize_ensemble_retriever(retrievers, weights):
    return EnsembleRetriever(retrievers=retrievers, weights=weights)


# ê° DBì— ëŒ€í•´ ë¦¬íŠ¸ë¦¬ë²„ì™€ BM25 ë¦¬íŠ¸ë¦¬ë²„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¶ì€ ë”•ì…”ë„ˆë¦¬
ensemble_retrievers = {
    "mct": (mct_retriever, mct_bm25_retriever),
    "month": (month_retriever, month_bm25_retriever),
    "wkday": (wkday_retriever, wkday_bm25_retriever),
    "mop": (mop_retriever, mop_bm25_retriever),
    "menus": (menus_retriever, menus_bm25_retriever),
    "visit": (visit_retriever, visit_bm25_retriever),
    "kakaomap_reviews": (kakaomap_reviews_retriever, kakaomap_reviews_bm25_retriever),
}

# Ensemble retrievers ì´ˆê¸°í™”ë¥¼ ëª…í™•í•˜ê²Œ
ensemble_retrievers = {
    name: initialize_ensemble_retriever(
        retrievers=ensemble_retrievers[name],
        weights=[0.6, 0.4],
    )
    for name in ensemble_retrievers.keys()
}

@st.cache_data
def flexible_function_call_search(query):
    try:
        # ì…ë ¥ ì¿¼ë¦¬ì˜ ì„ë² ë”©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        input_embedding = embedding.embed_query(query)

        # ë¦¬íŠ¸ë¦¬ë²„ì™€ ì„¤ëª…ì„ ì •ì˜
        retrievers_info = {
            "mct": {
                "retriever": mct_retriever,
                "description": "ì‹ë‹¹ ì •ë³´ ë° ì—°ì´ìš© ë¹„ì¤‘ ë° ê¸ˆì•¡ ë¹„ì¤‘",
            },
            "month": {
                "retriever": month_retriever,
                "description": "ê´€ê´‘ì§€ ì›”ë³„ ì¡°íšŒìˆ˜",
            },
            "wkday": {
                "retriever": wkday_retriever,
                "description": "ì£¼ë³„ ì¼ë³„ ì¡°íšŒìˆ˜ ë° ì—°ë ¹ë³„ ì„±ë³„ë³„ ì„ í˜¸ë„",
            },
            "mop": {
                "retriever": mop_retriever,
                "description": "ê´€ê´‘ì§€ ì „ì²´ ê°ì„±ë¶„ì„ ë°ì´í„°",
            },
            "menus": {
                "retriever": menus_retriever,
                "description": "ì‹ë‹¹ëª… ë° ë©”ë‰´ ë° ê¸ˆì•¡",
            },
            "visit": {
                "retriever": visit_retriever,
                "description": "ê´€ê´‘ì§€ í•µì‹¬ í‚¤ì›Œë“œ ë° ì •ë³´",
            },
            "kakaomap_reviews": {
                "retriever": kakaomap_reviews_retriever,
                "description": "ë¦¬ë·° ë°ì´í„°",
            },
        }

        # ê° ë¦¬íŠ¸ë¦¬ë²„ì˜ ì„¤ëª…ì„ ì„ë² ë”©í•©ë‹ˆë‹¤.
        retriever_embeddings = {
            key: embedding.embed_query(info["description"])
            for key, info in retrievers_info.items()
        }

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = {
            key: util.cos_sim(input_embedding, embed).item()
            for key, embed in retriever_embeddings.items()
        }

        # ìœ ì‚¬ë„ê°€ ì„ê³„ê°’ ì´ìƒì¸ ë¦¬íŠ¸ë¦¬ë²„ ì„ íƒ
        similarity_threshold = 0.7
        selected_retrievers = sorted(
            [
                (key, sim)
                for key, sim in similarities.items()
                if sim > similarity_threshold
            ],
            key=lambda x: x[1],
            reverse=True,
        )

        # ì„ íƒëœ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì‚¬ìš©í•´ ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
        results = []
        for retriever_key, _ in selected_retrievers:
            try:
                retriever = retrievers_info[retriever_key]["retriever"]
                result = retriever.get_relevant_documents(query)
                results.extend(result)
            except Exception as e:
                print(f"{retriever_key} ë¦¬íŠ¸ë¦¬ë²„ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

        return results if results else "ê´€ë ¨ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


def generate_response_with_faiss(
    question,
    df,
    embeddings,
    model,
    embed_text,
    keywords,
    local,
    locations={
        "êµ¬ì¢Œ": "êµ¬ì¢Œ",
        "ëŒ€ì •": "ëŒ€ì •",
        "ì•ˆë•": "ì•ˆë•",
        "ìš°ë„": "ìš°ë„",
        "ì• ì›”": "ì• ì›”",
        "ì¡°ì²œ": "ì¡°ì²œ",
        "ì œì£¼ì‹œë‚´": "ì œì£¼ì‹œë‚´",
        "ì¶”ì": "ì¶”ì",
        "í•œë¦¼": "í•œë¦¼",
        "í•œê²½": "í•œê²½",
    },
    score=0,
    index_path=os.path.join(
        os.path.dirname(os.path.abspath(__file__)), "faiss_index.faiss"
    ),
    max_count=10,
    k=3,
    print_prompt=True,
):
    # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
    try:
        index = load_faiss_indexes(index_path)
    except Exception as e:
        return f"ì¸ë±ìŠ¤ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"

    # ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = embed_text(question).reshape(1, -1)

    # ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰
    distances, indices = index.search(query_embedding, k * 3)
    filtered_df = df.iloc[indices[0, :]].copy().reset_index(drop=True)

    # í‚¤ì›Œë“œ ë§¤í•‘
    keyword_map = {
        "ì°©í•œê°€ê²©ì—…ì†Œ": "ì°©í•œê°€ê²©ì—…ì†Œ",
        "ëŸ­ì…”ë¦¬íŠ¸ë˜ë¸”ì¸ì œì£¼": "ëŸ­ì…”ë¦¬íŠ¸ë˜ë¸”ì¸ì œì£¼",
        "ìš°ìˆ˜ê´€ê´‘ì‚¬ì—…ì²´": "ìš°ìˆ˜ê´€ê´‘ì‚¬ì—…ì²´",
        "ë¬´ì¥ì• ê´€ê´‘": "ë¬´ì¥ì• ê´€ê´‘",
        "ì•ˆì „ì—¬í–‰ìŠ¤íƒ¬í”„": "ì•ˆì „ì—¬í–‰ìŠ¤íƒ¬í”„",
        "í–¥í† ìŒì‹": "í–¥í† ìŒì‹",
        "í•œì‹": "í•œì‹",
        "ì¹´í˜": "ì¹´í˜",
        "í•´ë¬¼ëšë°°ê¸°": "í•´ë¬¼ëšë°°ê¸°",
        "ëª¸êµ­": "ëª¸êµ­",
        "í•´ì¥êµ­": "í•´ì¥êµ­",
        "ìˆ˜ì œë²„ê±°": "ìˆ˜ì œë²„ê±°",
        "í‘ë¼ì§€": "í‘ë¼ì§€",
        "í•´ì‚°ë¬¼": "í•´ì‚°ë¬¼",
        "ì¼ì‹": "ì¼ì‹",
    }

    # í‚¤ì›Œë“œ í•„í„°ë§
    if keywords in keyword_map:
        filtered_df = filtered_df[
            filtered_df["í•µì‹¬í‚¤ì›Œë“œ"].apply(lambda x: keyword_map[keywords] in x)
        ].reset_index(drop=True)
    if filtered_df.empty:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."

    # ì§€ì—­ í•„í„°ë§
    local = locations.get(local, "ê¸°íƒ€")
    filtered_df = filtered_df[filtered_df["ì§€ì—­"] == local].reset_index(drop=True)
    if filtered_df.empty:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."

    # í‰ì  í•„í„°ë§
    filtered_df = filtered_df[filtered_df["í‰ì "] >= score].reset_index(drop=True)
    if filtered_df.empty:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    reference_info = "\n".join(filtered_df["text"][:max_count])
    prompt = (
        f"ì§ˆë¬¸: {question} íŠ¹íˆ {local}ì„ ì„ í˜¸í•´\nì°¸ê³ í•  ì •ë³´:\n{reference_info}\nì‘ë‹µ:"
    )
    if print_prompt:
        print("-----------------------------" * 3)
        print(prompt)
        print("-----------------------------" * 3)

    # ì‘ë‹µ ìƒì„±
    response = model.generate_content(prompt)
    return response

@st.cache_data
# Google Generative AI API ì„¤ì •
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    temperature=0.2,  # ë” ë‚®ì€ temperatureë¡œ ì„¤ì •í•´ í• ë£¨ì‹œë„¤ì´ì…˜ ì¤„ì„
    top_p=0.85,  # top_pë¥¼ ì¡°ì •í•´ ë” ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹µë³€ ìƒì„±
    frequency_penalty=0.1,  # ê°™ì€ ë‹¨ì–´ì˜ ë°˜ë³µì„ ì¤„ì´ê¸° ìœ„í•´ íŒ¨ë„í‹° ì¶”ê°€
)

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

@st.cache_data
prompt_template = PromptTemplate(
    input_variables=["input_text", "search_results", "chat_history"],
    template="""
    ### ì—­í• 
    ë‹¹ì‹ ì€ ì œì£¼ë„ ë§›ì§‘ê³¼ ê´€ê´‘ì§€ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ë°›ì„ ë•Œ ë…¼ë¦¬ì ìœ¼ë¡œ ìƒê°í•œ í›„ ë‹¨ê³„ë³„ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    ë³µì¡í•œ ì§ˆë¬¸ì¼ìˆ˜ë¡ ì²œì²œíˆ ìƒê°í•˜ê³  ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œê·¼í•˜ê³  ì •ê²¨ìš´ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

    ### Chain of Thought ë°©ì‹ ì ìš©:
    1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    2. ì§ˆë¬¸ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
    3. ê·¸ í›„ì— ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë‚˜ ê²€ìƒ‰ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ì„± ìˆëŠ” ë§›ì§‘ê³¼ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    4. ë‹¨ê³„ë¥¼ ë‚˜ëˆ„ì–´ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.

    ### ì§€ì‹œì‚¬í•­
    1. ê²€ìƒ‰í•  ë‚´ìš©ì´ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´ ì‚¬ìš©ìì—ê²Œ ë°˜ë¬¸í•˜ì„¸ìš”. ì´ëŠ” ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤. ë‹¨, ë‘ë²ˆ ì´ìƒ ë°˜ë¬¸í•˜ì§€ ë§ˆì„¸ìš”. ë§Œì•½ ì‚¬ìš©ìê°€ ìœ„ì¹˜ë¥¼ ëª¨ë¥¸ë‹¤ë©´ ì œì¼ í‰ì ì´ ì¢‹ì€ 3ê°œì˜ ì‹ë‹¹+ì¹´í˜ì™€ 3ê°œì˜ ê´€ê´‘ì§€ë¥¼ ì•ˆë‚´í•´ì£¼ì„¸ìš”.
    2. ë‹µë³€ì„ í•˜ëŠ” ê²½ìš° ì–´ë–¤ ë¬¸ì„œë¥¼ ì¸ìš©í–ˆëŠ”ì§€ (í‚¤:ê°’) ì—ì„œ í‚¤ëŠ” ì œì™¸í•˜ê³  ê°’ë§Œ ë‹µë³€ ë’¤ì— ì–¸ê¸‰í•˜ì„¸ìš”.
      (mct_docs: ì‹ í•œì¹´ë“œ ê°€ë§¹ì  - ìš”ì‹ì—…, month_docs: ë¹„ì§“ì œì£¼ - ì›”ë³„ ì¡°íšŒìˆ˜, wkday_docs: ë¹„ì§“ì œì£¼ - ìš”ì¼ë³„ ì¡°íšŒìˆ˜, mop_docs: ê´€ê´‘ì§€ í‰ì ë¦¬ë·°, menu_docs: ì¹´ì¹´ì˜¤ë§µ ê°€ê²Œ ë©”ë‰´, visit_docs: ë¹„ì§“ì œì£¼ - ì—¬í–‰ì§€ ì •ë³´, kakaomap_reviews_docs: ì¹´ì¹´ì˜¤ë§µ ë¦¬ë·°)
    4. ì¶”ì²œ ì´ìœ ì™€ ê±°ë¦¬, ì†Œìš” ì‹œê°„, í•µì‹¬í‚¤ì›Œë“œ 3ê°œ, í‰ì ê³¼ ë¦¬ë·°ë“¤ë„ ë³´ì—¬ì£¼ì„¸ìš”. ë§Œì•½ ë¦¬ë·°ê°€ ì—†ëŠ” ê³³ì´ë¼ë©´ ("ì•„ì§ ì‘ì„±ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.") ë¼ê³  í•´ì£¼ì„¸ìš”.
    5. 4ë²ˆì˜ ì§€ì‹œì‚¬í•­ê³¼ í•¨ê»˜ íŒë§¤ ë©”ë‰´ 2ê°œ, ê°€ê²©ì„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.
    6. ì£¼ì†Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ê²€ìƒ‰ë˜ëŠ” ì¥ì†Œë¥¼ ì•„ë˜ ì˜ˆì‹œ ë§í¬ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
      - ë„¤ì´ë²„ ì§€ë„ í™•ì¸í•˜ê¸°: (https://map.naver.com/p/search/ì œì£¼ë„+<place>ì¥ì†Œëª…</place>)
    7. ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì‹ë‹¹ê³¼ ê´€ê´‘ì§€ëª…ì„ ì¶”ì²œí•´ì£¼ì–´ì•¼ í•˜ë©°, %%í‘ë¼ì§€ ë§›ì§‘, íšŸì§‘ 1 ë“± ê°€ê²Œëª…ì´ ëª…í™•í•˜ì§€ ì•Šì€ ë‹µë³€ì€ í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.
    8. ë‹µë³€ ë‚´ìš©ì— ë”°ë¼ í°íŠ¸ì‚¬ì´ì¦ˆ, ë¶ˆë ›, ìˆœì„œë¥¼ í™œìš©í•˜ê³  ë¬¸ë‹¨ì„ êµ¬ë¶„í•˜ì—¬ ê°€ë…ì„±ì´ ì¢‹ê²Œ í•´ì£¼ì„¸ìš”.

    ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©:
    {search_results}

    ëŒ€í™” ê¸°ë¡:
    {chat_history}

    ì‚¬ìš©ìì˜ ì§ˆë¬¸: {input_text}

    ë…¼ë¦¬ì ì¸ ì‚¬ê³  í›„ ì‚¬ìš©ìì—ê²Œ ì œê³µí•  ë‹µë³€:
    """,
)

# ì²´ì¸ ìƒì„±
chain = LLMChain(
    prompt=prompt_template,
    llm=llm,
    output_parser=StrOutputParser(),
)


# í†µí•©ëœ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def get_chatbot_response(query, memory, chain):
    try:
        # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
        search_results = flexible_function_call_search(query)
        if not search_results:
            return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        search_results_str = "\n".join(
            [doc.page_content for doc in search_results]
        ).strip()

        if not search_results_str:
            return "ê²€ìƒ‰ëœ ë‚´ìš©ì´ ì—†ì–´ì„œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
        chat_history = memory.load_memory_variables({}).get("chat_history", "")

        # LLMChainì— ì „ë‹¬í•  ì…ë ¥ ë°ì´í„° êµ¬ì„±
        input_data = {
            "input_text": query,
            "search_results": search_results_str,
            "chat_history": chat_history,
        }

        try:
            output = chain(input_data)
            output_text = output.get("text", str(output))
        except Exception as e:
            print(f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        # ëŒ€í™” ê¸°ë¡ì— ì…ë ¥ ë° ì¶œë ¥ ì €ì¥
        memory.save_context({"input": query}, {"output": output_text})
        return output_text

    except Exception as e:
        print(f"ê²€ìƒ‰ ë˜ëŠ” ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."


# # ì±—ë´‡ ëŒ€í™” ë£¨í”„ í•¨ìˆ˜ (ì½˜ì†”ìš©)
# def chat():
#     print("ì±—ë´‡ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. 'exit'ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
#     memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

#     while True:
#         query = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
#         if query.lower() == "exit":
#             print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
#             break

#         # í†µí•©ëœ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ì‚¬ìš©
#         response = get_chatbot_response(query, memory, chain)
#         print("\nì±—ë´‡ ì‘ë‹µ:", response)

# ì„¸ì…˜ ìƒíƒœ ì²´í¬ ë° ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []  # ë©”ì‹œì§€ ì´ˆê¸°í™”

# ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ ë°›ê¸°, label ì¶”ê°€
prompt = st.chat_input(
    "Say something", label="Chat Input", label_visibility="collapsed"
)
if prompt:
    # ì…ë ¥ë°›ì€ ì¿¼ë¦¬ë¡œ ì‘ë‹µ ìƒì„±
    response = get_chatbot_response(prompt, memory, chain)

    # ì…ë ¥ ë° ì‘ë‹µ ê²°ê³¼ë¥¼ UIì— ì¶œë ¥
    st.write(f"User: {prompt}")
    st.write(f"Chatbot: {response}")

# ì±—ë´‡ ì‹œì‘ ì‹œ ì´ì „ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
if __name__ == "__main__":
    st.session_state
