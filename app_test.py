import streamlit as st
import json
import multiprocessing

st.set_page_config(
    page_title="ê°ê·¤í†¡",
    page_icon="ğŸŠ",
    layout="wide",
)
from src.config import *
from src.ui import (
    initialize_streamlit_ui,
    display_main_image,
    setup_sidebar,
    setup_keyword_selection,
    setup_location_selection,
    setup_score_selection,
    clear_chat_history,
)
from src.data_loader import *
from src.models import *
from src.retrievers import *
from src.chatbot import *
from src.prompts import get_chat_prompt

from langchain.memory import ConversationBufferMemory

import gzip

# Google API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
google_api_key = st.secrets["google_api_key"]

# .json íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
retriever_file_paths = glob.glob(
    "/Users/naeun/bigcontest_chatbot/data/json_retrievers/*.json"
)


# ë¦¬íŠ¸ë¦¬ë²„ ë°ì´í„° ë¡œë“œ (ë³‘ë ¬í™” ì ìš©)
def load_retrievers_parallel(file_paths):
    # ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬íŠ¸ë¦¬ë²„ íŒŒì¼ì„ ë³‘ë ¬ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        retriever_data = pool.map(load_ensemble_retriever_from_json, file_paths)
    return retriever_data


# ì±„íŒ… ê¸°ë¡ ê´€ë¦¬ í•¨ìˆ˜
def manage_chat_history():
    if len(st.session_state.messages) > st.session_state.max_messages:
        st.session_state.messages = (
            st.session_state.messages[:2]
            + st.session_state.messages[-(st.session_state.max_messages - 2) :]
        )
        chat_history = st.session_state.memory.load_memory_variables({})["chat_history"]
        if len(chat_history) > st.session_state.max_messages:
            st.session_state.memory.clear()
            for msg in st.session_state.messages[2:]:
                if msg["role"] == "user":
                    st.session_state.memory.save_context(
                        {"input": msg["content"]}, {"output": ""}
                    )
                elif msg["role"] == "assistant":
                    st.session_state.memory.save_context(
                        {"input": ""}, {"output": msg["content"]}
                    )


# ë¦¬íŠ¸ë¦¬ë²„ ë°ì´í„° ë¡œë“œ
def load_retrievers():
    if "retriever_data" not in st.session_state:
        # retrievers.pyì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ í˜¸ì¶œí•˜ì—¬ ë°ì´í„° ë¡œë“œ
        retriever_data = load_ensemble_retriever_from_json(retriever_file_paths)
        if retriever_data:
            st.session_state.retriever_data = retriever_data
            st.session_state.retrievers = retriever_data  # "retrievers" í‚¤ ì´ˆê¸°í™”
            st.write("ëª¨ë“  JSON ë¦¬íŠ¸ë¦¬ë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.write("ë¦¬íŠ¸ë¦¬ë²„ ë¡œë“œ ì‹¤íŒ¨")
    else:
        retriever_data = st.session_state.retriever_data
    return retriever_data


# ë¦¬íŠ¸ë¦¬ë²„ ë¡œë“œ
retriever_data = load_retrievers()

# # ë¦¬íŠ¸ë¦¬ë²„ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆë‹¤ë©´ ì‚¬ìš©
# if retriever_data:
#     for key, ensemble_retriever in retriever_data.items():
#         st.write(f"ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ ({key}):", ensemble_retriever)


# Streamlit main function
def main():
    # Streamlit UI ì´ˆê¸°í™”
    initialize_streamlit_ui()

    # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    if "memory" not in st.session_state:
        st.session_state.memory = ConversationBufferMemory(memory_key="chat_history")

    # ì´ˆê¸° ë©”ì‹œì§€ í‘œì‹œ
    if "initialized" not in st.session_state:
        st.chat_message("assistant").markdown("ì–´ë–¤ ê³³ì„ ì°¾ì•„ì¤„ê¹Œ?")
        st.session_state.initialized = True

    # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    if "memory" not in st.session_state:
        st.session_state.memory = ConversationBufferMemory(memory_key="chat_history")

    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì–´ë–¤ ê³³ì„ ì°¾ì•„ì¤„ê¹Œ?"}
        ]

    # chain ë° retrievers ì´ˆê¸°í™”
    if "chain" not in st.session_state:
        llm = initialize_llm()
        prompt_template = get_chat_prompt()
        st.session_state.chain = create_chain(
            llm, prompt_template, memory=st.session_state.memory
        )

    # ë¦¬íŠ¸ë¦¬ë²„ ë¡œë“œ
    retrievers = load_retrievers()

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # ì±—ë´‡ ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response = get_chatbot_response(
                    user_input=prompt,
                    memory=st.session_state.memory,
                    chain=st.session_state.chain,
                    retrievers=st.session_state.retrievers,
                )
                st.markdown(response)
                st.session_state.messages.append(
                    {"role": "assistant", "content": response}
                )


if __name__ == "__main__":
    main()
