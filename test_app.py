import os
from dotenv import load_dotenv

import numpy as np
import pandas as pd
import streamlit as st
import langchain.chat_models

from transformers import AutoTokenizer, AutoModel
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
# from langchain.chains import ConversationChain
from sentence_transformers import SentenceTransformer
from langchain_google_genai import ChatGoogleGenerativeAI

import torch
import faiss

# .env íŒŒì¼ ê²½ë¡œ ì§€ì •
google_api_key = os.getenv("GOOGLE_API_KEY")


# CSV íŒŒì¼ê³¼ .npy íŒŒì¼ ê²½ë¡œ ì„¤ì •
csv_file_paths = [
    './data/review_documents.csv',
    './data/mct_documents.csv',
    './data/trrsrt_documents.csv'
]
dfs = [pd.read_csv(csv_file_path) for csv_file_path in csv_file_paths]

# FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ
faiss_index_path = './modules/faiss_index.index'

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ
faiss_index = faiss.read_index(faiss_index_path)

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ì˜ˆ: 'jhgan/ko-sroberta-multitask')
model_embedding = SentenceTransformer('jhgan/ko-sroberta-multitask')


# Google Generative AI API ì„¤ì •
chat_model = ChatGoogleGenerativeAI(model='gemini-1.5-flash',
                                    api_key='AIzaSyAnl8_XMJ-rJgZ4mGBqsUuq8A4jGESxPAo',
                                    temperature=0.3,  
                                    top_p=0.85,       
                                    frequency_penalty=0.1  
)

# ë©€í‹°í„´ ëŒ€í™”ë¥¼ ìœ„í•œ Memory ì„¤ì •
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# ë©€í‹°í„´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (COT ë°©ì‹ ì ìš©)
prompt_template = PromptTemplate(
    input_variables=["input_text", "search_results", "chat_history"],
    template="""..."""  # ì›ë³¸ í…œí”Œë¦¿ ë‚´ìš© ê·¸ëŒ€ë¡œ ì‚¬ìš©
)

# ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def search_faiss(query_embedding, k=5):
    # FAISSì—ì„œ ìœ ì‚¬í•œ ë²¡í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì›ë³¸ ë°ì´í„° ë°˜í™˜
    distances, indices = faiss_index.search(np.array(query_embedding, dtype=np.float32), k)
    search_results = []
    total_length = 0

    for idx in indices[0]:
        found = False
        for df in dfs:
            if total_length + len(df) > idx:
                if idx - total_length >= 0 and idx - total_length < len(df):
                    search_results.append(df.iloc[idx - total_length])
                found = True
                break
            total_length += len(df)
        if found:
            continue

    return search_results

# ëŒ€í™”í˜• ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(user_input):
    query_embedding = model_embedding.encode([user_input])
    search_results = search_faiss(query_embedding)
    search_results_str = "\n".join([result.to_string() for result in search_results])
    
    filled_prompt = prompt_template.format(
        input_text=user_input,
        search_results=search_results_str,
        chat_history=memory.load_memory_variables({})["chat_history"]
    )

    response_parts = []
    while filled_prompt:
        part = filled_prompt[:5000]
        filled_prompt = filled_prompt[5000:]

        response = chat_model.invoke([{"role": "user", "content": part}])
        response_parts.append(response.content)

        if len(response_parts) >= 3:
            break

    for part in response_parts:
        memory.save_context({"input": user_input}, {"output": part})

    return "\n".join(response_parts)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="jeju-chatbot", page_icon="ğŸŒ´")
st.title("ğŸŒ´ ğŸŒ´ ì œì£¼ë„ ì—¬í–‰ ë©”ì´íŠ¸ AI")

# ì‚¬ìš©ì ì…ë ¥ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì…ë ¥ì°½
st.write("ì œì£¼ë„ íŠ¹ê¸‰ ê°€ì´ë“œ! ë§›ì§‘ë¶€í„° ì¹´í˜, ê´€ê´‘ì§€ê¹Œì§€ ì›í•˜ëŠ” ê³³ì„ ë§í•´ë´!")
message = st.text_input("ì°¾ê³  ìˆëŠ” ì¥ì†Œì˜ íŠ¹ì§•ì„ ì•Œë ¤ì¤˜.", key="input")

# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
if 'history' not in st.session_state:
    st.session_state['history'] = []

if st.button("ì „ì†¡"):
    if message:
        try:
            # ëª¨ë¸ í˜¸ì¶œ ë° ì‘ë‹µ ë°›ê¸°
            response = generate_response(message)
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            st.session_state['history'].append({"user": message, "bot": response})
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥
if st.session_state['history']:
    for chat in st.session_state['history']:
        st.write(f"**ì‚¬ìš©ì**: {chat['user']}")
        st.write(f"**AI**: {chat['bot']}")
